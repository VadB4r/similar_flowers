{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:04:32.669506Z",
     "start_time": "2025-02-22T11:04:29.009389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg16\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(0)"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x224f2975fb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:04:32.700990Z",
     "start_time": "2025-02-22T11:04:32.671511Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "f42a4f9aaa453c2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:04:32.716778Z",
     "start_time": "2025-02-22T11:04:32.700990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 3\n",
    "batch_size = 128"
   ],
   "id": "a32155013313a9b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:04:32.748359Z",
     "start_time": "2025-02-22T11:04:32.716778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = datasets.ImageFolder(root = 'data',\n",
    "                           transform = Compose(\n",
    "                               [\n",
    "                                   Resize((224, 224)),\n",
    "                                   ToTensor()\n",
    "                               ]\n",
    "                           )\n",
    ")"
   ],
   "id": "e88543dffb8bea27",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:04:32.764160Z",
     "start_time": "2025-02-22T11:04:32.750366Z"
    }
   },
   "cell_type": "code",
   "source": "n_classes = len(data.classes)",
   "id": "1f963de019ba804f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T11:04:32.795746Z",
     "start_time": "2025-02-22T11:04:32.764160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_size = len(data)\n",
    "train_perc = 0.6\n",
    "val_perc = test_perc = 0.2\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(data,\n",
    " [\n",
    "     int(data_size * train_perc),\n",
    "     int(data_size * val_perc),\n",
    "     data_size - int(data_size * train_perc) - int(data_size * val_perc),\n",
    "  ]\n",
    "                                                             )\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ],
   "id": "75cdadacd29fb1f8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.076243Z",
     "start_time": "2025-02-22T09:50:18.490395Z"
    }
   },
   "cell_type": "code",
   "source": "vgg = vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").to(device)",
   "id": "f14f84e65694eb5d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.092029Z",
     "start_time": "2025-02-22T09:50:20.076243Z"
    }
   },
   "cell_type": "code",
   "source": "vgg.classifier",
   "id": "49fe0de3e173d2aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.107814Z",
     "start_time": "2025-02-22T09:50:20.092029Z"
    }
   },
   "cell_type": "code",
   "source": "vgg.classifier[6].out_features = n_classes",
   "id": "b8b89ea72e8ea8f5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.123603Z",
     "start_time": "2025-02-22T09:50:20.107814Z"
    }
   },
   "cell_type": "code",
   "source": "vgg.classifier",
   "id": "7aac81c8371fe63a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.139391Z",
     "start_time": "2025-02-22T09:50:20.123603Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.CrossEntropyLoss()",
   "id": "1c230d006e905d33",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.155184Z",
     "start_time": "2025-02-22T09:50:20.139391Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = optim.AdamW(vgg.parameters(), lr=0.001)",
   "id": "1c973057fd25afea",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T09:50:20.170975Z",
     "start_time": "2025-02-22T09:50:20.155184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, criterion, optimizer, num_epochs=25):\n",
    "    train_losses_per_epoch = []\n",
    "    val_losses_per_epoch = []\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_losses_per_batch = []\n",
    "        val_losses_per_batch = []\n",
    "    \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pred = model(images)\n",
    "            loss = criterion(pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses_per_batch.append(loss)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                pred = model(images)\n",
    "                loss = criterion(pred, labels)\n",
    "                val_losses_per_batch.append(loss)\n",
    "        \n",
    "        train_losses_per_epoch.append(torch.Tensor(train_losses_per_batch).mean())\n",
    "        val_losses_per_epoch.append(torch.Tensor(val_losses_per_batch).mean())\n",
    "        print(f\"{epoch + 1}: train_loss: {train_losses_per_epoch[-1]} val_loss: {val_losses_per_epoch[-1]}\")\n",
    "    \n",
    "    return (\n",
    "        train_losses_per_epoch,\n",
    "        val_losses_per_epoch\n",
    "    )"
   ],
   "id": "5b00babab14ce1ad",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T10:15:30.232012Z",
     "start_time": "2025-02-22T09:50:20.172981Z"
    }
   },
   "cell_type": "code",
   "source": "train_loss, val_loss = train(vgg, criterion, optimizer, epochs)",
   "id": "d8f0ca51cc4b36e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: train_loss: 8.025720596313477 val_loss: 6.761537075042725\n",
      "2: train_loss: 46.70078659057617 val_loss: 40.78505325317383\n",
      "3: train_loss: 19.90152931213379 val_loss: 5.845839500427246\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T10:15:31.250173Z",
     "start_time": "2025-02-22T10:15:30.244044Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(vgg, \"./models/vgg_flower_trained.pt\")",
   "id": "edab56d344db48b4",
   "outputs": [],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
